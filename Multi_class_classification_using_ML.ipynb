{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "I have seen video but it was very lengthy and complex. While I was doing calmcode course, i have seen using Linear regression and KNN approaches to construct models in Scikit learn course. I googled and found that we can construct \"Multi-class classification model\" using KNN approach. First, I uploaded the csv file to google colab manually using file sub-option on the left."
      ],
      "metadata": {
        "id": "Dj-GnFFFqdXH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps we have done:\n",
        "1. We decided on labels. We took \"INDIAN, FRENCH,\n",
        " JAPANESE, ITALIAN, MEXICAN, CHINESE, AMERICAN' labels.\n",
        "2. Then we have annotated labels using prodigy. We used the same textcat.manual but to prevent the multi labels, we used this command \"python -m prodigy textcat.manual cuisine_dataset C:\\Users\\abikki\\Documents\\HomeWork2\\data\\homework2_train.jsonl --label INDIAN,FRENCH,JAPANESE,ITALIAN,MEXICAN,CHINESE,AMERICAN --exclusive\n",
        "3. We have used 'exclusive' to pick only one label as there was both \"RELEVANT\" and \"IRRELEVANT\" with multi lables for the dataset. We used the training dataset and took some entries, labelled them and exported them as .json dataset.\n",
        "4. While annotating, immediately after selecting cuisine label, the value was accepted and we were not able to accept the values without giving labels,so we rejected unrrelevant data and dishes of other cuisines.\n",
        "5. We then converted the json dataset into csv dataset using an online tool.\n",
        "6. When we opened the csv file in MS Excel it was having uncessesary data like rejected entries with no cuisine names, session ids and labels. We even removed rejected entries.\n",
        "7. We removed all those data and kept only two columns.One is text and other is cuisine name.\n",
        "8. Then we contructed the basic model using KNN Approach after browsing internet to decide betwwen linear regressor or KNN.\n",
        "9. Doing calmcode course (Scikit learn) gave me idea to try constructing model using the Linear regressor and KNN instead of doing it in more complex and harder way as the YouTube video sited in the proposal document.\n",
        "10. Due to lack of time, we did not took lot of examples and due to another assignment, we were not able to submit this code before 12.00 but we tried and attaching this.\n",
        "11. We just wanted to code and build multi-classification model so that we get bonus points. We are happy and striving to learn and improve."
      ],
      "metadata": {
        "id": "2bUkL7-ny7aO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "i1VzT8sin8op"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# importing csv file as a dataframe for flexibility\n",
        "df = pd.read_csv('cuisine_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# displaying the first few rows of the DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoKwXIuMqc4T",
        "outputId": "9386aec7-65d8-4a56-b8ce-27f97651946f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text   cuisine\n",
            "0  Your sauce recipe has a lot of starch for the ...   CHINESE\n",
            "1  I like to dip saltines into Lipton tea that ha...   CHINESE\n",
            "2  Do they? I know very little about cooking curr...    INDIAN\n",
            "3  This is really good: Smoky Lentil Chili https:...  AMERICAN\n",
            "4  That's basically what I did :) I had been eati...  AMERICAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# 'text' is our text data (comments) and 'cuisine' is our target variable (cuisine names)\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df['text'])\n",
        "y = df['cuisine']\n",
        "\n",
        "# Split the data into training and test sets (training data-80% and testing data-20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "WGbwL5ozr4Po"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# creating an KNN classifier. Randomly taking n=3\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# training the model\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# predicting on the test set\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# evaluating the model\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agvoWWL-xtWh",
        "outputId": "f9a72693-6065-4d6c-c196-ab702efeb32f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got an accuracy of 35%. We did not focused on accuracy and we took just around 100 examples and we focused on constructing the model and tried to develop a multi class model for bonus marks. In that 100 data also, we splitted them into 80 (training data) and 20 (testing data)."
      ],
      "metadata": {
        "id": "G__VHYvtyhqQ"
      }
    }
  ]
}